{"env_info": "sys.platform: linux\nPython: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]\nCUDA available: False\nGCC: gcc (Ubuntu 11.2.0-7ubuntu2) 11.2.0\nPyTorch: 1.13.1\nPyTorch compiling details: PyTorch built with:\n  - GCC 9.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.14.1\nOpenCV: 4.7.0\nMMCV: 1.7.1\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: not available\nMMDetection: 2.28.1+6f9b311", "config": "optimizer = dict(\n    type='SGD',\n    lr=0.01,\n    momentum=0.9,\n    weight_decay=0.0005,\n    nesterov=True,\n    paramwise_cfg=dict(norm_decay_mult=0.0, bias_decay_mult=0.0))\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(\n    policy='YOLOX',\n    warmup='exp',\n    by_epoch=False,\n    warmup_by_epoch=True,\n    warmup_ratio=1,\n    warmup_iters=5,\n    num_last_epochs=15,\n    min_lr_ratio=0.05)\nrunner = dict(type='EpochBasedRunner', max_epochs=300)\ncheckpoint_config = dict(interval=10)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [\n    dict(type='YOLOXModeSwitchHook', num_last_epochs=15, priority=48),\n    dict(type='SyncNormHook', num_last_epochs=15, interval=10, priority=48),\n    dict(\n        type='ExpMomentumEMAHook',\n        resume_from=None,\n        momentum=0.0001,\n        priority=49)\n]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = '/home/zach/Desktop/capstone/ISAC/deep-learning-training/checkpoints/yolox_tiny_8x8_300e_coco_20211124_171234-b4047906.pth'\nresume_from = None\nworkflow = [('train', 1)]\nopencv_num_threads = 0\nmp_start_method = 'fork'\nauto_scale_lr = dict(enable=False, base_batch_size=64)\nimg_scale = (640, 640)\nmodel = dict(\n    type='YOLOX',\n    input_size=(640, 640),\n    random_size_range=(10, 20),\n    random_size_interval=10,\n    backbone=dict(type='CSPDarknet', deepen_factor=0.33, widen_factor=0.375),\n    neck=dict(\n        type='YOLOXPAFPN',\n        in_channels=[96, 192, 384],\n        out_channels=96,\n        num_csp_blocks=1),\n    bbox_head=dict(\n        type='YOLOXHead', num_classes=1, in_channels=96, feat_channels=96),\n    train_cfg=dict(assigner=dict(type='SimOTAAssigner', center_radius=2.5)),\n    test_cfg=dict(score_thr=0.01, nms=dict(type='nms', iou_threshold=0.65)))\ndata_root = 'data/coco/'\ndataset_type = 'COCODataset'\ntrain_pipeline = [\n    dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),\n    dict(\n        type='RandomAffine',\n        scaling_ratio_range=(0.5, 1.5),\n        border=(-320, -320)),\n    dict(type='YOLOXHSVRandomAug'),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),\n    dict(\n        type='Pad',\n        pad_to_square=True,\n        pad_val=dict(img=(114.0, 114.0, 114.0))),\n    dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1), keep_empty=False),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\ntrain_dataset = dict(\n    type='MultiImageMixDataset',\n    dataset=dict(\n        type='CocoDataset',\n        ann_file='data/coco/annotations/instances_train2017.json',\n        img_prefix='data/coco/train2017/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True)\n        ],\n        filter_empty_gt=False),\n    pipeline=[\n        dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),\n        dict(\n            type='RandomAffine',\n            scaling_ratio_range=(0.5, 1.5),\n            border=(-320, -320)),\n        dict(type='YOLOXHSVRandomAug'),\n        dict(type='RandomFlip', flip_ratio=0.5),\n        dict(type='Resize', img_scale=(640, 640), keep_ratio=True),\n        dict(\n            type='Pad',\n            pad_to_square=True,\n            pad_val=dict(img=(114.0, 114.0, 114.0))),\n        dict(\n            type='FilterAnnotations', min_gt_bbox_wh=(1, 1), keep_empty=False),\n        dict(type='DefaultFormatBundle'),\n        dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n    ])\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(416, 416),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Pad',\n                pad_to_square=True,\n                pad_val=dict(img=(114.0, 114.0, 114.0))),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    persistent_workers=True,\n    train=dict(\n        type='MultiImageMixDataset',\n        dataset=dict(\n            type='CocoDataset',\n            ann_file='/home/zach/fiftyone/coco-2017/train/labels.json',\n            img_prefix='/home/zach/fiftyone/coco-2017/train/data',\n            pipeline=[\n                dict(type='LoadImageFromFile'),\n                dict(type='LoadAnnotations', with_bbox=True)\n            ],\n            filter_empty_gt=False,\n            classes=('person', )),\n        pipeline=[\n            dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),\n            dict(\n                type='RandomAffine',\n                scaling_ratio_range=(0.5, 1.5),\n                border=(-320, -320)),\n            dict(type='YOLOXHSVRandomAug'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(type='Resize', img_scale=(640, 640), keep_ratio=True),\n            dict(\n                type='Pad',\n                pad_to_square=True,\n                pad_val=dict(img=(114.0, 114.0, 114.0))),\n            dict(\n                type='FilterAnnotations',\n                min_gt_bbox_wh=(1, 1),\n                keep_empty=False),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n        ]),\n    val=dict(\n        type='CocoDataset',\n        ann_file='/home/zach/fiftyone/coco-2017/validation/labels.json',\n        img_prefix='/home/zach/fiftyone/coco-2017/validation/data',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(416, 416),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Pad',\n                        pad_to_square=True,\n                        pad_val=dict(img=(114.0, 114.0, 114.0))),\n                    dict(type='DefaultFormatBundle'),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ],\n        classes=('person', )),\n    test=dict(\n        type='CocoDataset',\n        ann_file='/home/zach/fiftyone/coco-2017/validation/labels.json',\n        img_prefix='/home/zach/fiftyone/coco-2017/validation/data',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(416, 416),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Pad',\n                        pad_to_square=True,\n                        pad_val=dict(img=(114.0, 114.0, 114.0))),\n                    dict(type='DefaultFormatBundle'),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ],\n        classes=('person', )))\nmax_epochs = 300\nnum_last_epochs = 15\ninterval = 10\nevaluation = dict(\n    save_best='auto', interval=10, dynamic_intervals=[(285, 1)], metric='bbox')\nclasses = ('person', )\nBASE_PATH = '/home/zach/fiftyone/coco-2017/'\nwork_dir = './work_dirs/yolox_tiny_person'\nauto_resume = False\ngpu_ids = [0]\n", "seed": 140650219, "exp_name": "yolox_tiny_person.py", "hook_msgs": {}}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "data_time": 0.06744, "loss_cls": 4.11137, "loss_bbox": 2.2471, "loss_obj": 3.71626, "loss": 10.07473, "time": 1.39076}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.0, "data_time": 0.00603, "loss_cls": 4.04331, "loss_bbox": 2.24939, "loss_obj": 3.49058, "loss": 9.78328, "time": 0.82846}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.0, "data_time": 0.00618, "loss_cls": 3.7578, "loss_bbox": 2.33129, "loss_obj": 3.24037, "loss": 9.32946, "time": 0.5503}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.0, "data_time": 0.00601, "loss_cls": 3.78235, "loss_bbox": 2.24581, "loss_obj": 3.46757, "loss": 9.49572, "time": 1.05903}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.0, "data_time": 0.00611, "loss_cls": 3.36703, "loss_bbox": 2.22713, "loss_obj": 3.24557, "loss": 8.83973, "time": 0.91086}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.0, "data_time": 0.00609, "loss_cls": 2.63964, "loss_bbox": 2.34059, "loss_obj": 3.24761, "loss": 8.22783, "time": 0.71753}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.0, "data_time": 0.00614, "loss_cls": 1.92852, "loss_bbox": 2.22743, "loss_obj": 2.90748, "loss": 7.06342, "time": 0.92135}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.0, "data_time": 0.00624, "loss_cls": 1.45249, "loss_bbox": 2.20115, "loss_obj": 2.83755, "loss": 6.49119, "time": 0.85852}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.0, "data_time": 0.00583, "loss_cls": 1.20669, "loss_bbox": 2.18025, "loss_obj": 2.75314, "loss": 6.14007, "time": 0.79447}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.0, "data_time": 0.00608, "loss_cls": 1.02768, "loss_bbox": 2.12531, "loss_obj": 2.68649, "loss": 5.83948, "time": 1.24654}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.0, "data_time": 0.00618, "loss_cls": 0.93819, "loss_bbox": 2.10771, "loss_obj": 2.38296, "loss": 5.42885, "time": 1.01944}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.0, "data_time": 0.00628, "loss_cls": 0.90108, "loss_bbox": 2.18337, "loss_obj": 2.35076, "loss": 5.43521, "time": 0.84401}
{"mode": "train", "epoch": 1, "iter": 650, "lr": 0.0, "data_time": 0.00623, "loss_cls": 0.82852, "loss_bbox": 2.11299, "loss_obj": 2.2158, "loss": 5.1573, "time": 1.01085}
{"mode": "train", "epoch": 1, "iter": 700, "lr": 0.0, "data_time": 0.00632, "loss_cls": 0.79232, "loss_bbox": 2.07457, "loss_obj": 2.22658, "loss": 5.09347, "time": 1.2116}
{"mode": "train", "epoch": 1, "iter": 750, "lr": 0.0, "data_time": 0.00619, "loss_cls": 0.75576, "loss_bbox": 2.111, "loss_obj": 2.03464, "loss": 4.90139, "time": 0.92284}
{"mode": "train", "epoch": 1, "iter": 800, "lr": 0.0, "data_time": 0.00644, "loss_cls": 0.74261, "loss_bbox": 2.082, "loss_obj": 2.14512, "loss": 4.96973, "time": 1.21233}
{"mode": "train", "epoch": 1, "iter": 850, "lr": 0.0, "data_time": 0.00645, "loss_cls": 0.71654, "loss_bbox": 2.07783, "loss_obj": 1.89646, "loss": 4.69082, "time": 1.09951}
{"mode": "train", "epoch": 1, "iter": 900, "lr": 1e-05, "data_time": 0.00633, "loss_cls": 0.7199, "loss_bbox": 2.095, "loss_obj": 1.90945, "loss": 4.72436, "time": 1.03411}
{"mode": "train", "epoch": 1, "iter": 950, "lr": 1e-05, "data_time": 0.00637, "loss_cls": 0.70115, "loss_bbox": 2.11257, "loss_obj": 1.84309, "loss": 4.65681, "time": 0.88803}
{"mode": "train", "epoch": 1, "iter": 1000, "lr": 1e-05, "data_time": 0.00634, "loss_cls": 0.66272, "loss_bbox": 2.06118, "loss_obj": 1.76905, "loss": 4.49296, "time": 1.1249}
{"mode": "train", "epoch": 1, "iter": 1050, "lr": 1e-05, "data_time": 0.00674, "loss_cls": 0.67427, "loss_bbox": 2.07108, "loss_obj": 1.83212, "loss": 4.57746, "time": 1.15155}
{"mode": "train", "epoch": 1, "iter": 1100, "lr": 1e-05, "data_time": 0.00635, "loss_cls": 0.65502, "loss_bbox": 2.08054, "loss_obj": 1.66958, "loss": 4.40514, "time": 0.79393}
{"mode": "train", "epoch": 1, "iter": 1150, "lr": 1e-05, "data_time": 0.0065, "loss_cls": 0.64049, "loss_bbox": 2.07201, "loss_obj": 1.70821, "loss": 4.42071, "time": 0.99759}
{"mode": "train", "epoch": 1, "iter": 1200, "lr": 1e-05, "data_time": 0.00658, "loss_cls": 0.63707, "loss_bbox": 2.09454, "loss_obj": 1.61817, "loss": 4.34979, "time": 0.79855}
{"mode": "train", "epoch": 1, "iter": 1250, "lr": 1e-05, "data_time": 0.00648, "loss_cls": 0.62572, "loss_bbox": 2.14395, "loss_obj": 1.61464, "loss": 4.38432, "time": 0.65998}
{"mode": "train", "epoch": 1, "iter": 1300, "lr": 1e-05, "data_time": 0.00664, "loss_cls": 0.61314, "loss_bbox": 2.08256, "loss_obj": 1.58624, "loss": 4.28194, "time": 0.70733}
{"mode": "train", "epoch": 1, "iter": 1350, "lr": 1e-05, "data_time": 0.00664, "loss_cls": 0.61726, "loss_bbox": 2.09313, "loss_obj": 1.71982, "loss": 4.43021, "time": 1.07536}
