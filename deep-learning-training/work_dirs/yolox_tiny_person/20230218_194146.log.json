{"env_info": "sys.platform: linux\nPython: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]\nCUDA available: False\nGCC: gcc (Ubuntu 11.2.0-7ubuntu2) 11.2.0\nPyTorch: 1.13.1\nPyTorch compiling details: PyTorch built with:\n  - GCC 9.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.14.1\nOpenCV: 4.7.0\nMMCV: 1.7.1\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: not available\nMMDetection: 2.28.1+6f9b311", "config": "optimizer = dict(\n    type='SGD',\n    lr=0.01,\n    momentum=0.9,\n    weight_decay=0.0005,\n    nesterov=True,\n    paramwise_cfg=dict(norm_decay_mult=0.0, bias_decay_mult=0.0))\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(\n    policy='YOLOX',\n    warmup='exp',\n    by_epoch=False,\n    warmup_by_epoch=True,\n    warmup_ratio=1,\n    warmup_iters=5,\n    num_last_epochs=15,\n    min_lr_ratio=0.05)\nrunner = dict(type='EpochBasedRunner', max_epochs=300)\ncheckpoint_config = dict(interval=10)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [\n    dict(type='YOLOXModeSwitchHook', num_last_epochs=15, priority=48),\n    dict(type='SyncNormHook', num_last_epochs=15, interval=10, priority=48),\n    dict(\n        type='ExpMomentumEMAHook',\n        resume_from=None,\n        momentum=0.0001,\n        priority=49)\n]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = '/home/zach/Desktop/capstone/ISAC/deep-learning-training/checkpoints/yolox_tiny_8x8_300e_coco_20211124_171234-b4047906.pth'\nresume_from = None\nworkflow = [('train', 1)]\nopencv_num_threads = 0\nmp_start_method = 'fork'\nauto_scale_lr = dict(enable=False, base_batch_size=64)\nimg_scale = (640, 640)\nmodel = dict(\n    type='YOLOX',\n    input_size=(640, 640),\n    random_size_range=(10, 20),\n    random_size_interval=10,\n    backbone=dict(type='CSPDarknet', deepen_factor=0.33, widen_factor=0.375),\n    neck=dict(\n        type='YOLOXPAFPN',\n        in_channels=[96, 192, 384],\n        out_channels=96,\n        num_csp_blocks=1),\n    bbox_head=dict(\n        type='YOLOXHead', num_classes=1, in_channels=96, feat_channels=96),\n    train_cfg=dict(assigner=dict(type='SimOTAAssigner', center_radius=2.5)),\n    test_cfg=dict(score_thr=0.01, nms=dict(type='nms', iou_threshold=0.65)))\ndata_root = 'data/coco/'\ndataset_type = 'COCODataset'\ntrain_pipeline = [\n    dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),\n    dict(\n        type='RandomAffine',\n        scaling_ratio_range=(0.5, 1.5),\n        border=(-320, -320)),\n    dict(type='YOLOXHSVRandomAug'),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),\n    dict(\n        type='Pad',\n        pad_to_square=True,\n        pad_val=dict(img=(114.0, 114.0, 114.0))),\n    dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1), keep_empty=False),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\ntrain_dataset = dict(\n    type='MultiImageMixDataset',\n    dataset=dict(\n        type='CocoDataset',\n        ann_file='data/coco/annotations/instances_train2017.json',\n        img_prefix='data/coco/train2017/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True)\n        ],\n        filter_empty_gt=False),\n    pipeline=[\n        dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),\n        dict(\n            type='RandomAffine',\n            scaling_ratio_range=(0.5, 1.5),\n            border=(-320, -320)),\n        dict(type='YOLOXHSVRandomAug'),\n        dict(type='RandomFlip', flip_ratio=0.5),\n        dict(type='Resize', img_scale=(640, 640), keep_ratio=True),\n        dict(\n            type='Pad',\n            pad_to_square=True,\n            pad_val=dict(img=(114.0, 114.0, 114.0))),\n        dict(\n            type='FilterAnnotations', min_gt_bbox_wh=(1, 1), keep_empty=False),\n        dict(type='DefaultFormatBundle'),\n        dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n    ])\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(416, 416),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Pad',\n                pad_to_square=True,\n                pad_val=dict(img=(114.0, 114.0, 114.0))),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=48,\n    workers_per_gpu=48,\n    persistent_workers=True,\n    train=dict(\n        type='MultiImageMixDataset',\n        dataset=dict(\n            type='CocoDataset',\n            ann_file='/home/zach/fiftyone/coco-2017/train/labels.json',\n            img_prefix='/home/zach/fiftyone/coco-2017/train/data',\n            pipeline=[\n                dict(type='LoadImageFromFile'),\n                dict(type='LoadAnnotations', with_bbox=True)\n            ],\n            filter_empty_gt=False,\n            classes=('person', )),\n        pipeline=[\n            dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),\n            dict(\n                type='RandomAffine',\n                scaling_ratio_range=(0.5, 1.5),\n                border=(-320, -320)),\n            dict(type='YOLOXHSVRandomAug'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(type='Resize', img_scale=(640, 640), keep_ratio=True),\n            dict(\n                type='Pad',\n                pad_to_square=True,\n                pad_val=dict(img=(114.0, 114.0, 114.0))),\n            dict(\n                type='FilterAnnotations',\n                min_gt_bbox_wh=(1, 1),\n                keep_empty=False),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n        ]),\n    val=dict(\n        type='CocoDataset',\n        ann_file='/home/zach/fiftyone/coco-2017/validation/labels.json',\n        img_prefix='/home/zach/fiftyone/coco-2017/validation/data',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(416, 416),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Pad',\n                        pad_to_square=True,\n                        pad_val=dict(img=(114.0, 114.0, 114.0))),\n                    dict(type='DefaultFormatBundle'),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ],\n        classes=('person', )),\n    test=dict(\n        type='CocoDataset',\n        ann_file='/home/zach/fiftyone/coco-2017/validation/labels.json',\n        img_prefix='/home/zach/fiftyone/coco-2017/validation/data',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(416, 416),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Pad',\n                        pad_to_square=True,\n                        pad_val=dict(img=(114.0, 114.0, 114.0))),\n                    dict(type='DefaultFormatBundle'),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ],\n        classes=('person', )))\nmax_epochs = 300\nnum_last_epochs = 15\ninterval = 10\nevaluation = dict(\n    save_best='auto', interval=10, dynamic_intervals=[(285, 1)], metric='bbox')\nclasses = ('person', )\nBASE_PATH = '/home/zach/fiftyone/coco-2017/'\nwork_dir = './work_dirs/yolox_tiny_person'\nauto_resume = False\ngpu_ids = [0]\n", "seed": 1318907814, "exp_name": "yolox_tiny_person.py", "hook_msgs": {}}
